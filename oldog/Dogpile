#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Jul 25 11:51:25 2019

@author: jonahcullen
"""


import argparse
import os
import csv
from collections import defaultdict
import gzip
import shutil
import json
import string
import random
import textwrap
#import numpy as np

refs = ["canfam3", "canfam4"]

def make_arg_parser():
    parser = argparse.ArgumentParser(
        prog="Dogpile",
        add_help=False,
        description=(
            "Dogpile generates all required input to process FASTQs to gVCF \n"
            "following GATK best practices. For each sample (and associated \n"
            "FASTQ pair), Dogpile outputs a directory structure organized by \n"
            "breed, wherein GATK pipeline input are contained by sample ID."
        )
    )
           #formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    required = parser.add_argument_group('required arguments')
    optional = parser.add_argument_group('optional arguments')
#   required.add_argument(
#           "-msi",
#            metavar="",
#            default=argparse.SUPPRESS,
#           action="store_true",
#           help="Include flag to use MSI (as opposed to local names/paths)")
    required.add_argument(
        "-m", "--meta",
        default=argparse.SUPPRESS,
        metavar="\b",
        required=True,
        help="csv of meta data and user ID to UMN ID conversions"
    )
    required.add_argument(
        "-f", "--fastqs",
        default=argparse.SUPPRESS,
        metavar="\b",
        required=True,
        help="list of full path of all fastqs"
    )
    required.add_argument(
        "-o", "--out",
        default=argparse.SUPPRESS,
        metavar="\b",
        required=True,
        help="path to out dir"
    )
    optional.add_argument(
        "-r", "--ref",
        nargs="?",
        const="CANFAM4",
        default="CANFAM4",
        choices=refs,
        help="select canfam reference to use - "+ \
            " or ".join(refs) + " [default: canfam4]",
        metavar=""
    )
    optional.add_argument(
        "-i", "--ids",
       #default=argparse.SUPPRESS,
        action="store_true",
       #metavar="\b",
       #required=True,
        help="file containing list of UMN dog IDs to process"
    )
    optional.add_argument(
        "-h", "--help",
        action="help",
        default=argparse.SUPPRESS,
        help="show this help message and exit"
    )

    return parser.parse_args()


# prepare dictionary containing all dog data and paths to fastqs
def prepare_dictionary(dog_meta, proc_dir, fq_paths):
    
    d = defaultdict(list)
    
    with open(dog_meta) as ids:
        reader = csv.reader(ids, delimiter=',')
        next(reader, None)
        for line in reader:
            d[line[-1]].extend(line[:-1])
            
            # add directory path to list
            dog_path = os.path.join(proc_dir,
                                    line[1],
                                    line[0])
            d[line[-1]].append(dog_path)
    
    with open(fq_paths) as fqs:
        for line in fqs:
            line = line.strip()
            tmp = os.path.basename(line)
            fq_id = tmp.split("_")[0]
            
            if "R1" in line:
                if os.path.exists(line):
                    if fq_id in d.keys():
                        d[fq_id].append(os.path.realpath(line))
                        d[fq_id].append(os.path.realpath(line).replace("R1", "R2"))
    return d

# prepare directories function
def setup_dirs(d):
    
    for v in d.values():
        os.makedirs(v[3], exist_ok=True)


# modify json 
# def extract_pu(s):
#     """ extracts platform unit from fastq header """
#     with gzip.open(s, "rt") as f:
#         head = f.readline().strip().split(":")
#         return f"{head[2]}.{head[3]}.{head[-1]}"

# THIS ALL NEEDS WORK...
def extract_pu(s):
    """ extracts platform unit from fastq header """
    with gzip.open(s, "rt") as f:
        head = f.readline().strip()
        if head.startswith("@SRR"): # handle SRR fastqs from NCBI
            return f"{head.split('.')[0][1:]}.NA.NA"
        elif head.startswith("@HWI"): # older MiSeq (?) fastqs...
            head = head.split(":")
            return f"{head[2]}.{head[3]}.NA"
        else: # or "standard" illumina headers...
            head = head.split(":")
            return f"{head[2]}.{head[3]}.{head[-1]}"


def deliver_cromwell_files(d, temps):
    
    for v in d.values():
        
        home = os.path.join("/panfs/roc/groups/0/fried255/fried255/working",
                            ref.lower(),
                            v[1],
                            v[0])
        dog_out = os.path.join(scratch,v[1],v[0])
        
        # modify and deliever fq to unmapped bam json
        fq_temp = os.path.join(temps,
                               f"fastq-to-gvcf.{ref}_TEMPLATE.json")
        fq_dog = os.path.join(v[3],
                               f"fastq-to-gvcf.{v[1]}.{v[0]}.{ref.lower()}.json")
        
        with open(fq_temp, "r") as infile, \
             open(fq_dog, "w") as outfile:
            
            json_data = json.load(infile)
            s = "ConvertPairedFastQsToGvcf_GATK4"
            
            n_reads = len(v[4::2])
            
            json_data[f"{s}.out_path"] = os.path.join(v[3], "bam/unmerged")
            json_data[f"{s}.ubam_list_name"] = f"{v[0]}_unmapped_bam"
            json_data[f"{s}.readgroup_name"] = [f"{v[0]}_{string.ascii_uppercase[i]}" 
                                                for i in range(0, n_reads)]
            json_data[f"{s}.sample_name"] = [v[0]] * n_reads
            json_data[f"{s}.fastq_1"] = [i for i in v[4::2] if "R1" in i]
            json_data[f"{s}.fastq_2"] = [i for i in v[5::2] if "R2" in i]
            json_data[f"{s}.library_name"] = [f"Illumina-{v[0]}"] * n_reads
            json_data[f"{s}.platform_unit"] = list(map(lambda x: extract_pu(x), v[4::2]))
            json_data[f"{s}.flowcell"] = [i.split(".")[0] for i in list(map(lambda x: extract_pu(x), v[4::2]))]
            json_data[f"{s}.run_date"] = ["2016-09-01T02:00:00+0200"] * n_reads
            json_data[f"{s}.platform_name"] = ["illumina"] * n_reads
            json_data[f"{s}.sequencing_center"] = ["unknown"] * n_reads
            json_data[f"{s}.ubam_list_name"] = f"{v[0]}_unmapped_bam"
            json_data[f"{s}.primary_path"] = os.path.join(home)
            json_data[f"{s}.sample"] = v[0]
            json_data[f"{s}.flowcell_unmapped_bams_list"] = os.path.join(dog_out, 
                                                                         "bam/unmerged", 
                                                                         v[0]+"_unmapped_bam.list")
            json_data[f"{s}.MarkDuplicates.tmp_dir"] = os.path.join("/dev/shm/", v[0]+".md.tmp")
            json_data[f"{s}.GatherBamFiles.bam_out"] = os.path.join(dog_out,
                                                                    "bam")
            # still necessary due to sample name stuff...should fix though
            for i in [("bam","bam"), ("bam_index","bai")]:
                json_data[f"{s}.input_{i[0]}"] = os.path.join(dog_out,
                                                              "bam",
                                                              v[0]+f".{ref.lower()}.{i[1]}")
            
            outfile.write((json.dumps(json_data, indent=2)))
                        
        # move wdl files
        for i in os.listdir(temps):
            if "fastq-to-gvcf.wdl" in i:
                src = os.path.join(temps, i)
                dst = os.path.join(v[3], i)
                if not os.path.exists(dst):
                    shutil.copy(src, dst)
            
        

def quote():
    with open(os.path.dirname(os.path.abspath(__file__))+"/.quotes") as f:
        lines = f.readlines()
        return random.choice(lines).strip()


#def deliver_pbs(d):
#    
#    for v in d.values():
#        
#        pbs = os.path.join(v[3], f"{v[1]}.{v[0]}.frankenflow.pbs")
#        
#        dst = os.path.join(scratch, 
#                         v[1], 
#                         v[0], 
#                         "cromwell.conf")
#        src = os.path.join(temp_dir, "cromwell.conf")
#        if not os.path.exists(dst):
#            shutil.copy(src, dst)
#        
#        home = os.path.join("/panfs/roc/groups/0/fried255/fried255/working",
#                            v[1],
#                            v[0])
#        
#        header = (
#                  "#!/bin/bash -l\n"
#                  "#PBS -l walltime=96:00:00,nodes=1:ppn=12,mem=62gb\n"
#                  "#PBS -m abe\n"
#                  "#PBS -M cull0084@umn.edu\n"
#                  f"#PBS -o $PBS_JOBID.{v[1]}.{v[0]}.frankenflow.out\n"
#                  f"#PBS -e $PBS_JOBID.{v[1]}.{v[0]}.frankenflow.err\n"
#                  f"#PBS -N {v[1]}.{v[0]}.frankenflow.pbs\n"
#                  "#PBS -q mesabi\n"
#                )
#    
#        with open(pbs, "w") as f:
#            print(header, file=f)
#            fill = "#"+"-"*79
#            print("set -e\n",file=f)
#            print("export PATH=/panfs/roc/groups/0/fried255/shared/.local/bin:$PATH\n",file=f)
#            print("cd $PBS_O_WORKDIR\n",file=f)
#            print(fill + "\n" +
#                  f"{'#'.center(0)}" + 
#                  f"Fire bad. {v[0]} ({v[1]}) good.".center(80), file=f)
#            print(fill.center(80)+"\n", file=f)
#            
#            print(f"java -Dconfig.file={dst} \\\n" +
#                  f" -jar {cromwell} \\\n" +
#                  " run ./fastq-to-gvcf.wdl \\\n" +
#                  f" -i ./fastq-to-gvcf.{v[1]}.{v[0]}.json\n",
#                  file=f)
#            
#            print(f"mkdir -p {os.path.join(home,'jobs')}\n" +
#                  f"cp -t {os.path.join(home,'jobs')} *.{{pbs,wdl,json,conf,err,out}}\n",
#                  file=f)
#            print(f'RunSync -d {v[0]} -b {v[1]} -o "$PBS_O_WORKDIR"\n', file=f)
#            print(fill, file=f)
#            for line in textwrap.wrap(quote(), width=50):
#                print("#".center(0)+line.center(79), file=f)
#            print(fill+"\n", file=f)              


def deliver_slurm(d):
    
    for v in d.values():
        slurm = os.path.join(v[3], f"{v[1]}.{v[0]}.frankenflow.slurm")
        
        # send cromwell.conf to individual dir...
        # should modify this (and other functions) to simply point to one
        # common configuration file - eg ~/.config/Dogpile/cromwell.conf
        dst = os.path.join(scratch, 
                         v[1], 
                         v[0], 
                         "cromwell.conf")
        src = os.path.join(temp_dir, "cromwell.conf")
        if not os.path.exists(dst):
            shutil.copy(src, dst)
            # modify copied version of cromwell.conf to include user email
            with open(dst, "r") as file:
                filedata = file.read()
                filedata = filedata.replace(
                                            "USER_EMAIL", 
                                            f"{os.environ['USER']}@umn.edu"
                                            )
            with open(dst, "w") as file:
                file.write(filedata)
        
        home = os.path.join("/panfs/roc/groups/0/fried255/fried255/working",
                            ref.lower(),
                            v[1],
                            v[0])
        
        # SBATCH directives 
        header = (
            "#!/bin/bash -l\n"
            "#SBATCH -t 60:00:00\n"
            "#SBATCH --nodes=1\n"
            "#SBATCH --ntasks-per-node=1\n"
            "#SBATCH --cpus-per-task=12\n"
            "#SBATCH --mem=32gb\n"
            "#SBATCH --mail-type=ALL\n"
            f"#SBATCH --mail-user={os.environ['USER']}@umn.edu\n"
            f"#SBATCH --job-name {v[1]}.{v[0]}.frankenflow.slurm\n"
            f"#SBATCH -o %j.{v[1]}.{v[0]}.frankenflow.out\n"
            f"#SBATCH -e %j.{v[1]}.{v[0]}.frankenflow.err\n"
        )             
     
        # slurm submission body 
        with open(slurm, "w") as f:
            print(header, file=f)
            fill = "#"+"-"*79
            print("set -e\n",file=f)
            print("export PATH=/panfs/roc/groups/0/fried255/shared/.local/bin:$PATH\n",file=f)
            print("cd $SLURM_SUBMIT_DIR\n",file=f)
            print(fill + "\n" +
                  f"{'#'.center(0)}" + 
                  f"Fire bad. {v[0]} ({v[1]}) good.".center(80), file=f)
            print(fill.center(80)+"\n", file=f)
            
            print(f"java -Dconfig.file={dst} \\\n" +
                  f" -jar {cromwell} \\\n" +
                  " run ./fastq-to-gvcf.wdl \\\n" +
                  f" -i ./fastq-to-gvcf.{v[1]}.{v[0]}.{ref.lower()}.json\n",
                  file=f)
            
            print(f"mkdir -p {os.path.join(home,'jobs')}\n" +
                  f"cp -t {os.path.join(home,'jobs')} *.{{slurm,wdl,json,conf,err,out}}\n",
                  file=f)
           #print(f'RunSync -r {ref.lower()} -d {v[0]} -b {v[1]} -o "$SLURM_SUBMIT_DIR"\n', file=f)
            print(f"sbatch  --mail-user={os.environ['USER']}@umn.edu \\\n" +
                  f' --export=BREED={v[1]},DOG_ID={v[0]},REF={ref.lower()},DOG_DIR="$SLURM_SUBMIT_DIR" \\\n' +
                  f' {sync}\n\nwait\n', file=f)
            print(fill, file=f)
            for line in textwrap.wrap(quote(), width=50):
                print("#".center(0)+line.center(79), file=f)
            print(fill+"\n", file=f)              

#${BREED}/${DOG_ID}/${REF}
#${DOG_DIR}

def main():

    d = prepare_dictionary(dog_meta, scratch, fq_paths)
    # subset d based on dog ids in dogs_in list    
    sub_d = {}
    if dogs_in:
        with open(dogs_in) as f:
            for line in f:
                line = line.strip()
                for k,v in d.items():
                    if line in v[0]:
                        if line not in sub_d:
                            sub_d[k] = v
            print(f"{len(sub_d)} dogs setup for processing")
    else:
        sub_d = d
        print(f"{len(sub_d)} dogs setup for processing")
 
    setup_dirs(sub_d)
    deliver_cromwell_files(sub_d, temp_dir)
    deliver_slurm(sub_d)    


if __name__ == '__main__':
     
#    if sys.version_info[0] < 3:
#        raise Exception('Python 3+ is required')
#        sys.exit()
    
    args = make_arg_parser()    

    dog_meta = os.path.abspath(args.meta)
    fq_paths = os.path.abspath(args.fastqs)
    scratch = os.path.abspath(args.out)
    ref = args.ref.upper()

    # sync job
    sync = "/panfs/roc/groups/0/fried255/shared/gatk4_workflow/SyncDogs/sync.slurm"

    if args.ids:
        dogs_in = os.path.abspath(args.ids)
    else:
        dogs_in = None
   #msi = args.msi
    
    # check if scratch dir exists
    if not os.path.exists(scratch):
        os.makedirs(scratch)
        print(f"{scratch} created!")
        
    for i in [dog_meta, fq_paths]:
        if not os.path.exists(i):
            print(f"WARNING: {os.path.basename(i)} does not exist - check" +
                   " file path")
    
    primary = f"/panfs/roc/groups/0/fried255/fried255/working/{ref.lower()}"
    cromwell = "/panfs/roc/groups/0/fried255/shared/gatk4_workflow/tools/cromwell-40.jar"
    temp_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "templates")
 
    main()
